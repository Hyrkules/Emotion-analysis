{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif du projet est de classifier l'émotion d'une personne à partir de l'expression de son visage.\n",
    "\n",
    "Le dataset que nous avons choisi est composé de 35 887 images classifiée en 7 catégories [neutre, colère, heureux, dégouté, effrayé, triste, surpris]. Ensuite le dataset est divisé en 2 dossier train et validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "# Import du dataset, la seed correspond à la randomisation des données pour l'entraînement\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'C:/Users/helou/Documents/Master_data_ia/M2/S2/DL/serl_project/images/train',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'C:/Users/helou/Documents/Master_data_ia/M2/S2/DL/serl_project/images/validation',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer nous avons choisi d'effectuer notre entraînement avec un réseau créé \"from scratch\", il est composé de \n",
    "10 couches.\n",
    "Le rescaling permet normaliser les pixels pour qu'ils passent de 0 à 255 en 0 à 1.\n",
    "Les couches de convolution permettent d'extraires les informations des images.\n",
    "Les couches de pooling vont réduire les dimensions des images traitées.\n",
    "La couche de flatten permet de passer des couches convolutives aux couches denses.\n",
    "Les couches denses Permettent d'interpréter les caratéristique des images pour faciliter la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with neurons\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de compiler ce modèle, nous avons utilisé l'optimiser adam, qui permet de mettre les poids à jour pendant l'entraînement.\n",
    "La fonction de loss va permettre de calculer l'efficacité de la classification.\n",
    "Enfin la métrique d'accuracy va nous permettre de faire évoluer notre modèle en fonction des résultats de celle-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons choisi de réaliser nos entraînements sur 30 époques à des fins de gains de temps pour réaliser différents tests. De plus nous avons constaté que 30 époques étaient largement suffisante pour atteindre un maximum local (souvent à 5-6 époques le modèle n'évolue plus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "model.save('./deep_learning_model_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur ce premier entraînement, on voit clairement un problème d'overfitting, en effet, la précision est extrêment élevée sur le dataset d'entraînement (0.93), tandis que sur celui de validation la valeus va stagner aux alentour de 0.42. De plus la validation loss augmente de plus en plus.\n",
    "\n",
    "Nous avons donc testé un deuxième modèle, \"plus léger\" car il comporte une couches de moins. Ici le but est de réduire l'overfit.\n",
    "On y a ensuite rajouté un dropout pour faire perdre de l'apprentissage aux poids : cela réduit également l'overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),  # Dropout layer\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats ne sont pas bons, on remarque qu'à la troisième époque, on pert déjà de la précision lors de la validation tandis qu'elle augmente pour la précision du train. On retrouve notre soucis d'overfiting.\n",
    "\n",
    "Dans un soucis de trouver la solution optimale et essayer de résoudre le problème d'overfit, nous avons également tester de construire un modèle à partir d'un modèle pré-entraîné. Ici nous utiliserons ResNet50.\n",
    "\n",
    "Ici, on laisse le modèle tel-quel, sans modification des poids pendant l'entraînement.\n",
    "On rajoute à Resnet 4 couches :\n",
    "    -  Un pooling pour réduire les dimensions de l'image traitée\n",
    "    -  Une couche dense de 128 neuronnes, appliquant une non-linéarité\n",
    "    -  Une couche de dropout pour réduire l'overfit en oubliant l'apprentissage de certaines couches\n",
    "    -  Une couche dense de 7 neuronnes permettant la classification, appliquant une normalisation des données.\n",
    "Enfin, une fonction de callback est utilisée pour arrêter l'entraînement si la validation loss n'évolue plus ou diminue. Cela permet de gagner du temps et éviter l'overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 Model\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False, \n",
    "    weights='imagenet', \n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 30\n",
    "history = model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle est celui qui nous a apporté les meilleurs résultats.\n",
    "\n",
    "On remarque que l'entraînement se termine au bout de 15 époques, la fonction d'early stopping prends effet car le modèle n'évolue plus. On atteint une précision de validation aux alentours de 0.55, ce qui est correcte.\n",
    "Cependant on pourrait espérer une précision plus élevée en améliorant les paramètres du modèle, notamment sa complexité avec plus de couches ou de neuronnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model on top\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 30\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dernier entraînement, sur une couche beaucoup moins dense, ne permet pas d'atteindre des meilleurs résultats. Au bout de la 3ème époque, la précision stagne et la précision de validation descend en-dessous de 0.4.\n",
    "On a testé un dropout de 0.3 et également une une densification de 64 (tf.keras.layers.Dense(64, activation='relu')). Mais les résultats ne sont pas meilleurs.\n",
    "\n",
    "Enfin voici un test sur un autre dataset, le RAF-DB dataset, corportant 15000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "# Import du dataset, la seed correspond à la randomisation des données pour l'entraînement\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'C:/Users/helou/Documents/Master_data_ia/M2/S2/DL/sentiment/DATASET/train',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'C:/Users/helou/Documents/Master_data_ia/M2/S2/DL/sentiment/DATASET/test',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Load ResNet50 Model\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False, \n",
    "    weights='imagenet', \n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 30\n",
    "history = model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que ce dataset est nettement plus performant, atteignant une précision de validation de 0.64\n",
    "\n",
    "Tableau des résultat par rapport au modèle ayant apporté les meilleurs résultats sur la validation accuracy :\n",
    "\n",
    "Batch size (1, 32, 64)\tNA, | 0,52 | 0,55\n",
    "Layer number (2, 3)\t0,55 | 0,37\n",
    "Densification des couches (32, 64, 128)\t0,32 | 0,47 | 0,52\n",
    "Dropout (0,1, 0,2, 0.3, 0,5)\t0,52 | 0,55 | 0.54 | 0,42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour conclure sur les modèles from scratch et ResNet50, on atteint un taux de précision supérieur à 50%, ce qui reste peu car cela représente une chance sur deux de faire une bonne prédiction.\n",
    "Cela est principalement dû à un overfitting qui nous empêchent d'atteindre des résultats pertinents. D'ailleurs on remarque également qu'un autre dataset est plus performant. Prouvant que celui que nous avons sélectionné ne suffit pas.\n",
    "\n",
    "En comparaison, sur ce lien on retrouve un exemple d'entraînement https://www.kaggle.com/code/yasserhessein/emotion-recognition-with-resnet50. Ici le modèle comporte plus de couches de traitements qui sont moins denses car elles comportent 32 neuronnes.\n",
    "Ce modèle atteint une précision de validation de 0.86 ce qui est beaucoup plus que nos modèles.\n",
    "\n",
    "Cela signifie sûrement qu'un modèle plus complexe avec des couches moins denses permettrait d'obtenir de bons résultats, ainsi qu'un bon dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons présenté nos différents modèles,\n",
    "Voici un exemple de démo en direct qui pourrait être effectué. L'idée est d'activer la caméra de notre ordinateur pour detecter l'émotion du visage qui sera vu par celle-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = tf.keras.models.load_model('./deep_learning_model.h5')\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame to 180x180 to match the model's expected input\n",
    "    resized_frame = cv2.resize(frame, (180, 180))\n",
    "\n",
    "    # Preprocess the image as required by ResNet50\n",
    "    resized_frame = np.expand_dims(resized_frame, axis=0)  # Add batch dimension\n",
    "    resized_frame = preprocess_input(resized_frame)  # Preprocess the input as ResNet expects\n",
    "\n",
    "    # Predict the emotion\n",
    "    predictions = model.predict(resized_frame)\n",
    "    emotion_index = np.argmax(predictions)  # Assuming the model outputs a softmax layer\n",
    "\n",
    "    # Map the predicted labels to emotions\n",
    "    emotions = ['Happy', 'Sad', 'Angry', 'Surprised', 'Neutral', 'Disgust', 'Fear']  # Update this list as per your model\n",
    "    emotion = emotions[emotion_index]\n",
    "\n",
    "    # Display the resulting frame with the predicted emotion\n",
    "    cv2.putText(frame, f'Emotion: {emotion}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
